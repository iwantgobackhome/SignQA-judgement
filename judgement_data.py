import streamlit as st
import json
import random
import pandas as pd
from datetime import datetime

# --- ì•± ì„¤ì • ë° ìƒìˆ˜ ---
APP_TITLE = "ëŒ€í™” ë°ì´í„° ë‹¤ì¤‘ íŒŒì¼ í‰ê°€ ë„êµ¬"
EVAL_CRITERIA = [
    "1. User Aì˜ ë§ì€ ì œì‹œëœ ë°°ê²½ ìƒí™©ê³¼ í•˜ë‚˜ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ì¥ë©´ìœ¼ë¡œ ì˜ ì–´ìš¸ë¦¬ë‚˜ìš”?",
    "2. ìƒì„±ëœ ë°°ê²½ì˜ ë‚´ìš©ì€ í˜„ì‹¤ì ì´ê³  ëª…í™•í•˜ê²Œ ì´í•´í•˜ê¸° ì‰½ë‚˜ìš”?",
    "3. User Bì˜ ëŒ€ë‹µì€ User Aì˜ ë§ê³¼ ë°°ê²½ ìƒí™©(background)ì— ë…¼ë¦¬ì ìœ¼ë¡œ ì¼ê´€ì„± ìˆê²Œ ì˜ ì—°ê²°ë˜ë‚˜ìš”?",
    "4. User Bì˜ ëŒ€ë‹µì€ ë¬¸ë²•, ì–´íœ˜ ì‚¬ìš©ì´ ì ì ˆí•˜ê³  í‘œí˜„ì´ ì‹¤ì œ ëŒ€í™”ì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ë‚˜ìš”?",
    "5. ì´ ì „ì²´ ëŒ€í™”(User A - ë°°ê²½ - User B)ëŠ” ì˜ë¯¸ ìˆê³  ìì—°ìŠ¤ëŸ¬ì›Œì„œ ë°ì´í„°ì…‹ì— í¬í•¨í•  ê°€ì¹˜ê°€ ìˆë‚˜ìš”?"
]
SAMPLE_FRACTION = 0.1 # 10% ìƒ˜í”Œë§

# ì‚¬ìš©ìê°€ í‰ê°€í•  JSON íŒŒì¼ ëª©ë¡ (ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ ìˆ˜ì •í•´ì£¼ì„¸ìš”)
# ì˜ˆì‹œ: "data/processed_file_alpha.json"
# Streamlit Community Cloud ë°°í¬ ì‹œ, ì´ íŒŒì¼ë“¤ì´ GitHub ì €ì¥ì†Œ ë‚´ì— í•¨ê»˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
# ë˜ëŠ”, íŒŒì¼ ì—…ë¡œë“œ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìê°€ ì§ì ‘ íŒŒì¼ì„ ì˜¬ë¦¬ë„ë¡ ìˆ˜ì •í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
DATA_FILES = {
    "how2sign_train": "data/how2sign_train/filtered_final_data.json", # ì‹¤ì œ íŒŒì¼ëª… ë˜ëŠ” ê²½ë¡œë¡œ ë³€ê²½
    "how2sign_test": "data/how2sign_test/filtered_final_data.json", # ì‹¤ì œ íŒŒì¼ëª… ë˜ëŠ” ê²½ë¡œë¡œ ë³€ê²½
    "how2sign_val": "data/how2sign_val/filtered_final_data.json", # ì‹¤ì œ íŒŒì¼ëª… ë˜ëŠ” ê²½ë¡œë¡œ ë³€ê²½
    "openasl_data": "data/openasl_data/filtered_final_data.json"  # ì‹¤ì œ íŒŒì¼ëª… ë˜ëŠ” ê²½ë¡œë¡œ ë³€ê²½
}

# --- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---
@st.cache_data # ë°ì´í„° ë¡œë”©ì€ ìºì‹±
def load_json_data(file_path):
    """ì§€ì •ëœ ê²½ë¡œì˜ JSON íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        return data
    except FileNotFoundError:
        st.error(f"ì˜¤ë¥˜: '{file_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•˜ê±°ë‚˜, GitHub ì €ì¥ì†Œì— íŒŒì¼ì´ ì˜¬ë°”ë¥´ê²Œ í¬í•¨ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None
    except json.JSONDecodeError:
        st.error(f"ì˜¤ë¥˜: '{file_path}' íŒŒì¼ì´ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
        return None
    except Exception as e:
        st.error(f"'{file_path}' íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def get_sampled_data(data, fraction):
    """ë°ì´í„°ì—ì„œ ì§€ì •ëœ ë¹„ìœ¨ë§Œí¼ ëœë¤ ìƒ˜í”Œë§í•©ë‹ˆë‹¤. ìµœì†Œ 1ê°œëŠ” ìƒ˜í”Œë§í•©ë‹ˆë‹¤."""
    if not data:
        return []
    num_samples = int(len(data) * fraction)
    if len(data) > 0 and num_samples == 0:
        num_samples = 1 # ìµœì†Œ 1ê°œ ìƒ˜í”Œë§
    if num_samples > len(data):
        num_samples = len(data) # ìƒ˜í”Œ ìˆ˜ê°€ ì „ì²´ ë°ì´í„° ìˆ˜ë³´ë‹¤ í´ ìˆ˜ ì—†ìŒ
    return random.sample(data, num_samples)

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” í•¨ìˆ˜ ---
def initialize_session_state():
    """ì•±ì˜ ì„¸ì…˜ ìƒíƒœ ë³€ìˆ˜ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    if "current_eval_file_key" not in st.session_state: # í˜„ì¬ ì„ íƒëœ íŒŒì¼ì˜ 'í‚¤' (DATA_FILESì˜ í‚¤)
        st.session_state.current_eval_file_key = None
    if "sampled_data" not in st.session_state: # í˜„ì¬ íŒŒì¼ì˜ ìƒ˜í”Œë§ëœ ë°ì´í„°
        st.session_state.sampled_data = []
    if "current_item_index" not in st.session_state: # í˜„ì¬ í‰ê°€ ì¤‘ì¸ ì•„ì´í…œ ì¸ë±ìŠ¤
        st.session_state.current_item_index = 0
    if "evaluations_for_current_file" not in st.session_state: # í˜„ì¬ íŒŒì¼ì— ëŒ€í•œ í‰ê°€ ê²°ê³¼ ëˆ„ì 
        st.session_state.evaluations_for_current_file = []
    if "evaluation_of_current_file_complete" not in st.session_state:
        st.session_state.evaluation_of_current_file_complete = False
    if "all_collected_evaluations" not in st.session_state: # ëª¨ë“  íŒŒì¼ì˜ í‰ê°€ ê²°ê³¼ë¥¼ ì €ì¥ (ì„ íƒì )
        st.session_state.all_collected_evaluations = {} # {file_key: [evaluations]}

def reset_evaluation_state_for_new_file(file_key):
    """ìƒˆë¡œìš´ íŒŒì¼ì„ í‰ê°€í•˜ê¸° ìœ„í•´ ê´€ë ¨ ì„¸ì…˜ ìƒíƒœë¥¼ ì´ˆê¸°í™”/ì„¤ì •í•©ë‹ˆë‹¤."""
    st.session_state.current_eval_file_key = file_key
    file_path = DATA_FILES[file_key]
    all_data_for_file = load_json_data(file_path)
    if all_data_for_file is not None:
        st.session_state.sampled_data = get_sampled_data(all_data_for_file, SAMPLE_FRACTION)
        if not st.session_state.sampled_data:
            st.warning(f"'{file_key}' íŒŒì¼ì—ì„œ ìƒ˜í”Œë§ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    else:
        st.session_state.sampled_data = [] # ë¡œë“œ ì‹¤íŒ¨ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸
        
    st.session_state.current_item_index = 0
    st.session_state.evaluations_for_current_file = []
    st.session_state.evaluation_of_current_file_complete = False
    st.info(f"'{file_key}' íŒŒì¼ì— ëŒ€í•œ í‰ê°€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. ì´ {len(st.session_state.sampled_data)}ê°œì˜ ì•„ì´í…œì´ ìƒ˜í”Œë§ë˜ì—ˆìŠµë‹ˆë‹¤.")

# --- Streamlit ì•± UI êµ¬ì„± ---
st.set_page_config(page_title=APP_TITLE, layout="wide")
st.title(APP_TITLE)

initialize_session_state()

# --- ì‚¬ì´ë“œë°”: íŒŒì¼ ì„ íƒ ë° ê´€ë¦¬ ---
st.sidebar.header("íŒŒì¼ ì„ íƒ ë° ê´€ë¦¬")
selected_file_key_from_sidebar = st.sidebar.selectbox(
    "í‰ê°€í•  íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”:",
    options=["íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”..."] + list(DATA_FILES.keys()),
    index=0,
    key="sb_file_select"
)

if selected_file_key_from_sidebar != "íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”...":
    if st.session_state.current_eval_file_key != selected_file_key_from_sidebar:
        # ë‹¤ë¥¸ íŒŒì¼ì´ ì„ íƒë˜ë©´, í•´ë‹¹ íŒŒì¼ë¡œ í‰ê°€ ìƒíƒœ ì „í™˜
        reset_evaluation_state_for_new_file(selected_file_key_from_sidebar)
        st.rerun() # ìƒíƒœ ë³€ê²½ í›„ UI ì¦‰ì‹œ ì—…ë°ì´íŠ¸
    # ê°™ì€ íŒŒì¼ì´ ë‹¤ì‹œ ì„ íƒëœ ê²½ìš°ëŠ” í˜„ì¬ ìƒíƒœ ìœ ì§€ (ë°ì´í„° ì¬ë¡œë”© ë°©ì§€)
else: # "íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”..."ê°€ ì„ íƒëœ ê²½ìš° (ì´ˆê¸° ìƒíƒœ ë˜ëŠ” íŒŒì¼ ì„ íƒ í•´ì œ)
    if st.session_state.current_eval_file_key is not None: # ì´ì „ì— íŒŒì¼ì´ ì„ íƒëœ ìƒíƒœì˜€ë‹¤ë©´ ì´ˆê¸°í™”
        st.session_state.current_eval_file_key = None
        st.session_state.sampled_data = []
        st.session_state.current_item_index = 0
        st.session_state.evaluations_for_current_file = []
        st.session_state.evaluation_of_current_file_complete = False
        # st.rerun() # í•„ìš”ì‹œ ì¦‰ì‹œ UI ì—…ë°ì´íŠ¸

if st.sidebar.button("í˜„ì¬ íŒŒì¼ í‰ê°€ ì´ˆê¸°í™”/ë‹¤ì‹œ ì‹œì‘", key="btn_reset_current_file_eval"):
    if st.session_state.current_eval_file_key and st.session_state.current_eval_file_key != "íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”...":
        reset_evaluation_state_for_new_file(st.session_state.current_eval_file_key)
        st.success(f"'{st.session_state.current_eval_file_key}' íŒŒì¼ í‰ê°€ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.rerun()
    else:
        st.sidebar.warning("ì´ˆê¸°í™”í•  íŒŒì¼ì„ ë¨¼ì € ì„ íƒí•´ì£¼ì„¸ìš”.")

# --- ë©”ì¸ í‰ê°€ ì˜ì—­ ---
if not st.session_state.current_eval_file_key or st.session_state.current_eval_file_key == "íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”...":
    st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ í‰ê°€í•  íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
elif not st.session_state.sampled_data:
    st.warning(f"'{st.session_state.current_eval_file_key}' íŒŒì¼ì— ëŒ€í•œ ìƒ˜í”Œë§ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì´ ë¹„ì–´ìˆê±°ë‚˜ ë¡œë“œì— ì‹¤íŒ¨í–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
else:
    # í˜„ì¬ í‰ê°€í•  ì•„ì´í…œ ê°€ì ¸ì˜¤ê¸°
    if st.session_state.current_item_index < len(st.session_state.sampled_data):
        current_item = st.session_state.sampled_data[st.session_state.current_item_index]
        item_data_id = current_item.get("data_id", f"item_idx_{st.session_state.current_item_index}")

        st.header(f"'{st.session_state.current_eval_file_key}' íŒŒì¼ í‰ê°€ ì¤‘")
        st.subheader(f"ì•„ì´í…œ {st.session_state.current_item_index + 1} / {len(st.session_state.sampled_data)} (ID: {item_data_id})")
        
        # ëŒ€í™” ë‚´ìš© í‘œì‹œ
        with st.expander("User A ë°œí™”", expanded=True):
            st.markdown(f"> {current_item.get('User A', 'N/A')}")
        
        with st.expander("ë°°ê²½ì§€ì‹ (Background)", expanded=True):
            st.markdown(f"> {current_item.get('background', 'N/A')}")
        
        with st.expander("User B ì‘ë‹µ", expanded=True):
            st.markdown(f"> {current_item.get('User B', 'N/A')}")
        
        st.divider()
        
        # í‰ê°€ ì…ë ¥ í¼
        with st.form(key=f"eval_form_{st.session_state.current_eval_file_key}_{item_data_id}"):
            st.subheader("í‰ê°€ í•­ëª©")
            current_scores = {}
            for i, criterion in enumerate(EVAL_CRITERIA):
                current_scores[criterion] = st.radio(
                    label=criterion, 
                    options=list(range(1, 6)), 
                    index=2, # ê¸°ë³¸ê°’ 3ì 
                    horizontal=True, 
                    key=f"q_{i}_{item_data_id}"
                )
            
            comment = st.text_area("ì¶”ê°€ ì½”ë©˜íŠ¸ (ì„ íƒ ì‚¬í•­)", key=f"comment_{item_data_id}")
            
            submit_button = st.form_submit_button(label="í‰ê°€ ì œì¶œ ë° ë‹¤ìŒ ì•„ì´í…œ")

        if submit_button:
            evaluation_entry = {
                "original_file_key": st.session_state.current_eval_file_key,
                "original_file_path": DATA_FILES[st.session_state.current_eval_file_key],
                "data_id": item_data_id,
                "sampled_item_user_a": current_item.get('User A'),
                "sampled_item_background": current_item.get('background'),
                "sampled_item_user_b": current_item.get('User B'),
                "evaluation_scores": current_scores,
                "evaluator_comment": comment,
                "evaluation_timestamp": datetime.now().isoformat()
            }
            st.session_state.evaluations_for_current_file.append(evaluation_entry)
            
            # ì „ì²´ í‰ê°€ ê²°ê³¼ì—ë„ ì €ì¥ (ì„ íƒì  ê¸°ëŠ¥)
            if st.session_state.current_eval_file_key not in st.session_state.all_collected_evaluations:
                st.session_state.all_collected_evaluations[st.session_state.current_eval_file_key] = []
            st.session_state.all_collected_evaluations[st.session_state.current_eval_file_key].append(evaluation_entry)

            st.session_state.current_item_index += 1
            
            if st.session_state.current_item_index < len(st.session_state.sampled_data):
                st.success("í‰ê°€ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ í•­ëª©ì„ ì§„í–‰í•©ë‹ˆë‹¤.")
            else:
                st.session_state.evaluation_of_current_file_complete = True
                st.balloons()
                st.success(f"'{st.session_state.current_eval_file_key}' íŒŒì¼ì˜ ëª¨ë“  ì•„ì´í…œ í‰ê°€ ì™„ë£Œ!")
            st.rerun()

    elif st.session_state.evaluation_of_current_file_complete:
        st.header(f"ğŸ‰ '{st.session_state.current_eval_file_key}' íŒŒì¼ í‰ê°€ ì™„ë£Œ! ğŸ‰")
        st.write(f"ì´ {len(st.session_state.evaluations_for_current_file)}ê°œì˜ ì•„ì´í…œì— ëŒ€í•œ í‰ê°€ê°€ ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else: # current_item_index >= len(sampled_data) ì´ì§€ë§Œ ì•„ì§ ì™„ë£Œ í”Œë˜ê·¸ê°€ ì•ˆ ì„  ê²½ìš° (ì´ë¡ ìƒ ë„ë‹¬ ì•ˆí•¨)
        st.info("ëª¨ë“  ì•„ì´í…œ í‰ê°€ê°€ ì™„ë£Œëœ ê²ƒ ê°™ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ë‹¤ë¥¸ íŒŒì¼ì„ ì„ íƒí•˜ê±°ë‚˜ ê²°ê³¼ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.")


# --- í‰ê°€ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ ì„¹ì…˜ (í˜„ì¬ íŒŒì¼ì— ëŒ€í•œ ê²°ê³¼) ---
if st.session_state.current_eval_file_key and st.session_state.current_eval_file_key != "íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”...":
    if st.session_state.evaluations_for_current_file:
        st.divider()
        st.subheader(f"'{st.session_state.current_eval_file_key}' íŒŒì¼ í‰ê°€ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
        
        # DataFrameìœ¼ë¡œ ë³€í™˜
        df_results = pd.DataFrame(st.session_state.evaluations_for_current_file)
        
        # evaluation_scores ë”•ì…”ë„ˆë¦¬ë¥¼ ë³„ë„ ì»¬ëŸ¼ìœ¼ë¡œ í¼ì¹˜ê¸°
        # (ì£¼ì˜: ì»¬ëŸ¼ëª…ì´ ê¸¸ì–´ì§ˆ ìˆ˜ ìˆìŒ. í•„ìš”ì‹œ ì ìˆ˜ë§Œ ì¶”ì¶œí•˜ê±°ë‚˜ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬)
        try:
            scores_df = pd.json_normalize(df_results['evaluation_scores'])
            # ì»¬ëŸ¼ëª…ì— ì ‘ë‘ì‚¬ ì¶”ê°€ (ì˜ˆ: "score_1. ë§¥ë½ ì í•©ì„±")
            scores_df = scores_df.rename(columns={col: f"score_{col}" for col in scores_df.columns})
            df_final_for_download = pd.concat([df_results.drop(columns=['evaluation_scores']), scores_df], axis=1)
        except Exception: # ì ìˆ˜ ë°ì´í„°ê°€ ì—†ê±°ë‚˜ í˜•ì‹ì´ ë‹¤ë¥¼ ê²½ìš° ì›ë³¸ ìœ ì§€
            df_final_for_download = df_results

        # CSV ë‹¤ìš´ë¡œë“œ
        csv_data = df_final_for_download.to_csv(index=False).encode('utf-8-sig')
        st.download_button(
            label=f"CSV ë‹¤ìš´ë¡œë“œ ({len(st.session_state.evaluations_for_current_file)}ê°œ ê²°ê³¼)",
            data=csv_data,
            file_name=f"evaluations_{st.session_state.current_eval_file_key.replace(' ', '_')}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv",
            key=f"csv_download_{st.session_state.current_eval_file_key}"
        )

        # JSON ë‹¤ìš´ë¡œë“œ
        json_data = json.dumps(st.session_state.evaluations_for_current_file, ensure_ascii=False, indent=2)
        st.download_button(
            label=f"JSON ë‹¤ìš´ë¡œë“œ ({len(st.session_state.evaluations_for_current_file)}ê°œ ê²°ê³¼)",
            data=json_data,
            file_name=f"evaluations_{st.session_state.current_eval_file_key.replace(' ', '_')}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json",
            key=f"json_download_{st.session_state.current_eval_file_key}"
        )

# --- ì•± ì •ë³´ ---
st.sidebar.divider()
st.sidebar.markdown("---")
st.sidebar.info(f"{APP_TITLE}\n\nStreamlitì„ í™œìš©í•œ í‰ê°€ ë„êµ¬ì…ë‹ˆë‹¤.")
